{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxmUnrO-hclI",
        "outputId": "9ff8f9f4-92ce-4121-ac0c-30e61c0f2134"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym[toy_text]==0.25.2 in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[toy_text]==0.25.2) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[toy_text]==0.25.2) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[toy_text]==0.25.2) (0.0.8)\n",
            "Collecting pygame==2.1.0 (from gym[toy_text]==0.25.2)\n",
            "  Downloading pygame-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pygame\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.5.2\n",
            "    Uninstalling pygame-2.5.2:\n",
            "      Successfully uninstalled pygame-2.5.2\n",
            "Successfully installed pygame-2.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gym[toy_text]==0.25.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from time import sleep\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "mLJ7IqY3hdVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym"
      ],
      "metadata": {
        "id": "uKI90CmYhqCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grid = 5x5 grid, which gives us 25 possible taxi locations\n",
        "# There are four (4) locations that we can pick up and drop off a passenger: R, G, Y, B\n",
        "# taxi environment has 25 (taxi locations) x 5 passenger locations x 4 destinations = 500 total possible states\n",
        "env = gym.make(\"Taxi-v3\", render_mode ='ansi', new_step_api=True).env\n",
        "env.reset()\n",
        "print(env.render()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pgri2Mu6hr9l",
        "outputId": "7a4ad402-d358-4e83-c6a5-055bff84d4b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|\u001b[35mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : |\u001b[43m \u001b[0m: |\n",
            "|\u001b[34;1mY\u001b[0m| : |B: |\n",
            "+---------+\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Action Space {}\".format(env.action_space))\n",
        "print(\"State Space {}\".format(env.observation_space))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3L-8ggGlhynR",
        "outputId": "d7a1c758-1248-4cd3-b2c2-298a043dc388"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action Space Discrete(6)\n",
            "State Space Discrete(500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()\n",
        "state = env.encode(3, 1, 2, 0) # (taxi row, taxi column, passenger index, destination index)\n",
        "print(\"State:\", state)\n",
        "\n",
        "env.s = state\n",
        "print(env.render()[0])\n",
        "# blue letter represents the current passenger pick-up location, and the purple letter is the current destination"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8tyo8hriIPJ",
        "outputId": "ee37f85b-ac20-41ea-e610-34f35597ae6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State: 328\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|\u001b[35mY\u001b[0m| :\u001b[43m \u001b[0m|\u001b[34;1mB\u001b[0m: |\n",
            "+---------+\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.s = 328  # set environment to illustration's state\n",
        "epochs = 0\n",
        "penalties, reward = 0, 0\n",
        "frames = [] # for animation\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "    action = env.action_space.sample()\n",
        "    state, reward, done, truncated, info = env.step(action)\n",
        "    if reward==-10:\n",
        "        penalties += 1\n",
        "\n",
        "    # Put each rendered frame into dict for animation\n",
        "    frames.append({'frame': env.render(),'state': state,'action': action,'reward': reward})\n",
        "    epochs += 1\n",
        "\n",
        "print(\"Timesteps taken: {}\".format(epochs))\n",
        "print(\"Penalties incurred: {}\".format(penalties))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSKnuhetjWiQ",
        "outputId": "e645e535-405c-4323-beaf-304e746e3eed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timesteps taken: 1205\n",
            "Penalties incurred: 394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_frames(frames, time_sleep=.1):\n",
        "    for i, frame in enumerate(frames):\n",
        "        clear_output(wait=True)\n",
        "        print(frame['frame'][0])\n",
        "        print(f\"Timestep: {i + 1}\")\n",
        "        print(f\"State: {frame['state']}\")\n",
        "        print(f\"Action: {frame['action']}\")\n",
        "        print(f\"Reward: {frame['reward']}\")\n",
        "        sleep(time_sleep)"
      ],
      "metadata": {
        "id": "bd0R44LvkZ2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_frames(frames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "mLQesrU_kmy8",
        "outputId": "14fa160b-a65c-42ee-fa1b-0665bf5fc036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|\u001b[35mY\u001b[0m| : |\u001b[34;1m\u001b[43mB\u001b[0m\u001b[0m: |\n",
            "+---------+\n",
            "  (Dropoff)\n",
            "\n",
            "Timestep: 232\n",
            "State: 474\n",
            "Action: 5\n",
            "Reward: -1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-5c6fcc0dfb7e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-863846cbccff>\u001b[0m in \u001b[0;36mprint_frames\u001b[0;34m(frames, time_sleep)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Action: {frame['action']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Reward: {frame['reward']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_sleep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q learning"
      ],
      "metadata": {
        "id": "dv3X-HvGlpuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q_table = np.zeros([env.observation_space.n, env.action_space.n])"
      ],
      "metadata": {
        "id": "xjbhzGo-koPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\"\"\"Training the agent\"\"\"\n",
        "import random\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Hyperparameters\n",
        "alpha = 0.1\n",
        "gamma = 0.6\n",
        "epsilon = 0.1\n",
        "\n",
        "# For plotting metrics\n",
        "all_epochs = []\n",
        "all_penalties = []\n",
        "\n",
        "for i in range(1, 100001):\n",
        "    state = env.reset()\n",
        "    epochs, penalties, reward, = 0, 0, 0\n",
        "    done = False\n",
        "    while not done:\n",
        "        if random.uniform(0, 1) < epsilon:\n",
        "            action = env.action_space.sample() # Explore action space\n",
        "        else:\n",
        "            action = np.argmax(q_table[state]) # Exploit learned values\n",
        "        next_state, reward, done, truncated, info = env.step(action)\n",
        "        old_value = q_table[state, action]\n",
        "        next_max = np.max(q_table[next_state])\n",
        "        new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
        "        q_table[state, action] = new_value\n",
        "        if reward == -10:\n",
        "            penalties += 1\n",
        "        state = next_state\n",
        "        epochs += 1\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        clear_output(wait=True)\n",
        "        print(f\"Episode: {i}\")\n",
        "\n",
        "print(\"Training finished.\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEWvTETeloJV",
        "outputId": "c0d61913-eedc-49fd-c09b-832351ef3888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 100000\n",
            "Training finished.\n",
            "\n",
            "CPU times: user 2min 56s, sys: 12.8 s, total: 3min 8s\n",
            "Wall time: 3min 8s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Evaluate agent's performance after Q-learning\"\"\"\n",
        "total_epochs, total_penalties = 0, 0\n",
        "episodes = 100\n",
        "frames =[]\n",
        "\n",
        "for _ in range(episodes):\n",
        "    state = env.reset()\n",
        "    epochs, penalties, reward = 0, 0, 0\n",
        "    done = False\n",
        "    while not done:\n",
        "        action = np.argmax(q_table[state])\n",
        "        state, reward, done, truncated, info = env.step(action)\n",
        "        if reward == -10:\n",
        "            penalties += 1\n",
        "        # Put each rendered frame into dict for animation\n",
        "        frames.append({'frame': env.render(),'state': state,'action': action,'reward': reward})\n",
        "        epochs += 1\n",
        "    total_penalties += penalties\n",
        "    total_epochs += epochs\n",
        "\n",
        "print(f\"Results after {episodes} episodes:\")\n",
        "print(f\"Average timesteps per episode: {total_epochs / episodes}\")\n",
        "print(f\"Average penalties per episode: {total_penalties / episodes}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzhH5gCAlylj",
        "outputId": "3d8a4817-0642-4d89-9e6b-d25e3354c4bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 13.24\n",
            "Average penalties per episode: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_frames(frames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "RC1aAg-0l4wr",
        "outputId": "a2a39a64-e212-4856-c00e-07ea41366398"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|R: | : :\u001b[35m\u001b[42mG\u001b[0m\u001b[0m|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "  (East)\n",
            "\n",
            "Timestep: 553\n",
            "State: 97\n",
            "Action: 2\n",
            "Reward: -1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-5c6fcc0dfb7e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-863846cbccff>\u001b[0m in \u001b[0;36mprint_frames\u001b[0;34m(frames, time_sleep)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Action: {frame['action']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Reward: {frame['reward']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_sleep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B-LiBzwVnQ1N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}